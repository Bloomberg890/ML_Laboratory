{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n"
      ],
      "metadata": {
        "id": "Mo4xcGZFre4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luxft3PIrZqy",
        "outputId": "79aed557-1824-49d8-c4c1-52eed1627fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'english-handwritten-characters-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/english-handwritten-characters-dataset\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "3405    z\n",
            "3406    z\n",
            "3407    z\n",
            "3408    z\n",
            "3409    z\n",
            "Name: label, Length: 3410, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"dhruvildave/english-handwritten-characters-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(os.path.join(path, 'english.csv'))\n",
        "print(df[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZnBuyvSrtVL",
        "outputId": "1dd1e258-4b4c-457c-ba6e-a57d2446f73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (3410, 4096)\n",
            "y shape: (3410,)\n"
          ]
        }
      ],
      "source": [
        "img_size = 64  # resize to fixed size\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    fil = row['image']\n",
        "    label = row['label']\n",
        "    img_path = os.path.join(path, fil)\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        X.append(img)\n",
        "        y.append(label)\n",
        "\n",
        "X = np.array(X, dtype=\"float32\") / 255.0   # normalize safely\n",
        "X = X.reshape(-1, img_size * img_size)     # flatten after scaling\n",
        "\n",
        "y = np.array(y)\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGhvXaO6lwsC",
        "outputId": "710c1864-39f9-4f66-996e-688e190bcd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before normalization:\n",
            "min: 0 max: 255 unique: [  0 120 178 183 204 215 224 242 255]\n"
          ]
        }
      ],
      "source": [
        "print(\"Before normalization:\")\n",
        "print(\"min:\", img.min(), \"max:\", img.max(), \"unique:\", np.unique(img)[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igwv-lN4mNXc",
        "outputId": "2587f783-6815-4ea2-af27-fd1028b2e9c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X min: 0.0 X max: 1.0 X unique: [0.         0.00392157 0.01176471 0.01960784 0.02745098 0.03137255\n",
            " 0.03529412 0.04313726 0.05098039 0.05882353]\n"
          ]
        }
      ],
      "source": [
        "print(\"X min:\", X.min(), \"X max:\", X.max(), \"X unique:\", np.unique(X)[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT-933QdUXL4",
        "outputId": "d3c181d8-6a6b-4352-f362-a807b61e0c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({np.str_('0'): 55, np.str_('1'): 55, np.str_('2'): 55, np.str_('3'): 55, np.str_('4'): 55, np.str_('5'): 55, np.str_('6'): 55, np.str_('7'): 55, np.str_('8'): 55, np.str_('9'): 55, np.str_('A'): 55, np.str_('B'): 55, np.str_('C'): 55, np.str_('D'): 55, np.str_('E'): 55, np.str_('F'): 55, np.str_('G'): 55, np.str_('H'): 55, np.str_('I'): 55, np.str_('J'): 55, np.str_('K'): 55, np.str_('L'): 55, np.str_('M'): 55, np.str_('N'): 55, np.str_('O'): 55, np.str_('P'): 55, np.str_('Q'): 55, np.str_('R'): 55, np.str_('S'): 55, np.str_('T'): 55, np.str_('U'): 55, np.str_('V'): 55, np.str_('W'): 55, np.str_('X'): 55, np.str_('Y'): 55, np.str_('Z'): 55, np.str_('a'): 55, np.str_('b'): 55, np.str_('c'): 55, np.str_('d'): 55, np.str_('e'): 55, np.str_('f'): 55, np.str_('g'): 55, np.str_('h'): 55, np.str_('i'): 55, np.str_('j'): 55, np.str_('k'): 55, np.str_('l'): 55, np.str_('m'): 55, np.str_('n'): 55, np.str_('o'): 55, np.str_('p'): 55, np.str_('q'): 55, np.str_('r'): 55, np.str_('s'): 55, np.str_('t'): 55, np.str_('u'): 55, np.str_('v'): 55, np.str_('w'): 55, np.str_('x'): 55, np.str_('y'): 55, np.str_('z'): 55})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "print(Counter(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXB7EGmEsTFo",
        "outputId": "e9cdc273-915b-4adc-ab7f-e1537837b28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H'\n",
            " 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z'\n",
            " 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y_encoded_onehot = to_categorical(y_encoded)\n",
        "num_classes = y_encoded_onehot.shape[1]\n",
        "\n",
        "print(\"Classes:\", le.classes_)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded_onehot, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuGYGSarTWSH",
        "outputId": "2b2b838c-8702-44cc-f16d-977bd806a7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train min: 0.0\n",
            "X_train max: 1.0\n",
            "Unique values in X_train: [0.         0.00392157 0.01176471 0.01960784 0.02745098 0.03137255\n",
            " 0.03529412 0.04313726 0.05098039 0.05882353 0.06666667 0.07450981\n",
            " 0.08235294 0.09019608 0.09411765 0.09803922 0.10588235 0.11372549\n",
            " 0.12156863 0.1254902 ]\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train min:\", X_train.min())\n",
        "print(\"X_train max:\", X_train.max())\n",
        "print(\"Unique values in X_train:\", np.unique(X_train)[:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFbqaBmrscQ7",
        "outputId": "9049e169-aa56-4326-9992-4db2c90d2e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 completed\n",
            "Epoch 2/5 completed\n",
            "Epoch 3/5 completed\n",
            "Epoch 4/5 completed\n",
            "Epoch 5/5 completed\n",
            "PLA Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        11\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.33      0.09      0.14        11\n",
            "           3       0.00      0.00      0.00        11\n",
            "           4       0.17      0.09      0.12        11\n",
            "           5       0.00      0.00      0.00        11\n",
            "           6       0.00      0.00      0.00        11\n",
            "           7       0.00      0.00      0.00        11\n",
            "           8       0.00      0.00      0.00        11\n",
            "           9       0.24      0.73      0.36        11\n",
            "           A       0.00      0.00      0.00        11\n",
            "           B       0.00      0.00      0.00        11\n",
            "           C       0.00      0.00      0.00        11\n",
            "           D       0.50      0.09      0.15        11\n",
            "           E       0.00      0.00      0.00        11\n",
            "           F       0.00      0.00      0.00        11\n",
            "           G       0.00      0.00      0.00        11\n",
            "           H       0.38      0.27      0.32        11\n",
            "           I       0.00      0.00      0.00        11\n",
            "           J       0.00      0.00      0.00        11\n",
            "           K       0.00      0.00      0.00        11\n",
            "           L       0.00      0.00      0.00        11\n",
            "           M       0.00      0.00      0.00        11\n",
            "           N       0.00      0.00      0.00        11\n",
            "           O       0.33      0.09      0.14        11\n",
            "           P       0.27      0.82      0.41        11\n",
            "           Q       0.00      0.00      0.00        11\n",
            "           R       0.75      0.27      0.40        11\n",
            "           S       0.33      0.27      0.30        11\n",
            "           T       0.21      0.64      0.31        11\n",
            "           U       0.09      0.82      0.16        11\n",
            "           V       0.00      0.00      0.00        11\n",
            "           W       0.00      0.00      0.00        11\n",
            "           X       0.21      0.36      0.27        11\n",
            "           Y       0.00      0.00      0.00        11\n",
            "           Z       0.00      0.00      0.00        11\n",
            "           a       0.00      0.00      0.00        11\n",
            "           b       0.08      0.09      0.08        11\n",
            "           c       0.03      0.91      0.06        11\n",
            "           d       0.00      0.00      0.00        11\n",
            "           e       0.00      0.00      0.00        11\n",
            "           f       0.00      0.00      0.00        11\n",
            "           g       0.20      0.55      0.29        11\n",
            "           h       0.00      0.00      0.00        11\n",
            "           i       0.00      0.00      0.00        11\n",
            "           j       0.50      0.18      0.27        11\n",
            "           k       0.00      0.00      0.00        11\n",
            "           l       0.00      0.00      0.00        11\n",
            "           m       0.00      0.00      0.00        11\n",
            "           n       0.00      0.00      0.00        11\n",
            "           o       0.00      0.00      0.00        11\n",
            "           p       0.00      0.00      0.00        11\n",
            "           q       0.50      0.09      0.15        11\n",
            "           r       0.00      0.00      0.00        11\n",
            "           s       0.25      0.09      0.13        11\n",
            "           t       0.00      0.00      0.00        11\n",
            "           u       0.20      0.27      0.23        11\n",
            "           v       0.00      0.00      0.00        11\n",
            "           w       0.00      0.00      0.00        11\n",
            "           x       0.00      0.00      0.00        11\n",
            "           y       0.00      0.00      0.00        11\n",
            "           z       0.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.11       682\n",
            "   macro avg       0.09      0.11      0.07       682\n",
            "weighted avg       0.09      0.11      0.07       682\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "class PLA:\n",
        "    def __init__(self, input_dim, num_classes, lr=0.01, epochs=10):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.num_classes = num_classes\n",
        "        self.W = np.zeros((input_dim, num_classes))\n",
        "        self.b = np.zeros(num_classes)\n",
        "\n",
        "    def step_function(self, z):\n",
        "        return (z > 0).astype(int)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                xi = X[i]\n",
        "                target = np.argmax(y[i])\n",
        "                scores = np.dot(xi, self.W) + self.b\n",
        "                y_hat = np.argmax(scores)\n",
        "                if y_hat != target:\n",
        "                    self.W[:, target] += self.lr * xi\n",
        "                    self.W[:, y_hat] -= self.lr * xi\n",
        "            print(f\"Epoch {epoch+1}/{self.epochs} completed\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = np.dot(X, self.W) + self.b\n",
        "        return np.argmax(scores, axis=1)\n",
        "\n",
        "\n",
        "pla = PLA(input_dim=X_train.shape[1], num_classes=num_classes, lr=0.01, epochs=5)\n",
        "pla.fit(X_train, y_train)\n",
        "\n",
        "y_pred_pla = pla.predict(X_test)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"PLA Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_pla, target_names=le.classes_.astype(str)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmMY5XIzHvYC",
        "outputId": "949707bc-6f51-43ba-d0a1-1c1ae7b00c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " ...\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "0Xb_JxDbTpg3",
        "outputId": "e0ebbccf-f1f9-4b90-c609-c2b4a1a09d99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "classes_to_show = np.unique(y)[:10]  # pick 10 different classes\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "\n",
        "for idx, cls in enumerate(classes_to_show):\n",
        "    i = np.where(y == cls)[0][0]  # find first index of that class\n",
        "    ax = axes.flat[idx]\n",
        "    ax.imshow(X[i].reshape(img_size, img_size), cmap=\"gray\")\n",
        "    ax.set_title(f\"Label: {cls}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9tit0FjWoR0",
        "outputId": "c1764b38-6479-42f5-fb20-07b3f7c4b7c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape before one-hot: (2728, 62)\n",
            "Unique labels: [0. 1.]\n"
          ]
        }
      ],
      "source": [
        "print(\"y_train shape before one-hot:\", y_train.shape)\n",
        "print(\"Unique labels:\", np.unique(y_train[:20]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MTiNuBVslyb",
        "outputId": "d45b8acb-55f6-4176-edc6-0cea82365ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training MLP with activation=relu and optimizer=SGD\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.0122 - loss: 4.4467 - val_accuracy: 0.0205 - val_loss: 4.1313\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.0165 - loss: 4.1437 - val_accuracy: 0.0132 - val_loss: 4.1269\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.0143 - loss: 4.1277 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.0129 - loss: 4.1279 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.0149 - loss: 4.1276 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.0190 - loss: 4.1287 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.0173 - loss: 4.1276 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.0139 - loss: 4.1276 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.0151 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.0197 - loss: 4.1274 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.0165 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.0124 - loss: 4.1274 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.0148 - loss: 4.1276 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.0137 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.0208 - loss: 4.1272 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 16/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.0156 - loss: 4.1272 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 17/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.0134 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 18/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.0140 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 19/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.0140 - loss: 4.1276 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 20/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.0155 - loss: 4.1274 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "\n",
            " Training MLP with activation=relu and optimizer=Adam\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.0161 - loss: 5.4522 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.0141 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.0161 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.0141 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.0203 - loss: 4.1269 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.0116 - loss: 4.1274 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.0139 - loss: 4.1276 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.0138 - loss: 4.1271 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.0133 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0129 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.0190 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.0161 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.0152 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.0132 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.0110 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 16/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.0152 - loss: 4.1272 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 17/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0137 - loss: 4.1274 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 18/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.0143 - loss: 4.1274 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 19/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.0163 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 20/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0155 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "\n",
            " Training MLP with activation=relu and optimizer=RMSprop\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.0167 - loss: 7.8007 - val_accuracy: 0.0161 - val_loss: 4.2268\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.0155 - loss: 4.1486 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.0179 - loss: 4.1276 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.0173 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.0150 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1272\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.0116 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.0108 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.0173 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.0152 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.0135 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.0171 - loss: 4.1274 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.0108 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.0148 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.0195 - loss: 4.1274 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.0156 - loss: 4.1273 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 16/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.0137 - loss: 4.1274 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 17/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.0159 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 18/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.0114 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 19/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.0181 - loss: 4.1272 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "Epoch 20/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.0172 - loss: 4.1275 - val_accuracy: 0.0161 - val_loss: 4.1271\n",
            "\n",
            " Training MLP with activation=tanh and optimizer=SGD\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.0157 - loss: 4.5178 - val_accuracy: 0.0161 - val_loss: 4.3038\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.0130 - loss: 4.5571 - val_accuracy: 0.0191 - val_loss: 4.1895\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.0164 - loss: 4.4898 - val_accuracy: 0.0220 - val_loss: 4.1881\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.0169 - loss: 4.4520 - val_accuracy: 0.0161 - val_loss: 4.2081\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.0158 - loss: 4.4831 - val_accuracy: 0.0161 - val_loss: 4.1961\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.0151 - loss: 4.4081 - val_accuracy: 0.0161 - val_loss: 4.1911\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.0170 - loss: 4.4546 - val_accuracy: 0.0205 - val_loss: 4.1851\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.0154 - loss: 4.4337 - val_accuracy: 0.0191 - val_loss: 4.2396\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.0129 - loss: 4.4278 - val_accuracy: 0.0161 - val_loss: 4.2088\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.0151 - loss: 4.4191 - val_accuracy: 0.0161 - val_loss: 4.1952\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.0121 - loss: 4.3859 - val_accuracy: 0.0264 - val_loss: 4.1855\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.0270 - loss: 4.3291 - val_accuracy: 0.0176 - val_loss: 4.1853\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.0151 - loss: 4.3628 - val_accuracy: 0.0161 - val_loss: 4.1503\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.0185 - loss: 4.3147 - val_accuracy: 0.0161 - val_loss: 4.1533\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.0191 - loss: 4.3328 - val_accuracy: 0.0543 - val_loss: 4.0964\n",
            "Epoch 16/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.0131 - loss: 4.2478 - val_accuracy: 0.0235 - val_loss: 4.0971\n",
            "Epoch 17/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.0216 - loss: 4.2147 - val_accuracy: 0.0293 - val_loss: 4.0522\n",
            "Epoch 18/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.0231 - loss: 4.1750 - val_accuracy: 0.0484 - val_loss: 3.9674\n",
            "Epoch 19/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.0276 - loss: 4.1255 - val_accuracy: 0.0689 - val_loss: 3.8485\n",
            "Epoch 20/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.0478 - loss: 4.0218 - val_accuracy: 0.0367 - val_loss: 3.8039\n",
            "\n",
            " Training MLP with activation=tanh and optimizer=Adam\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.0104 - loss: 4.7601 - val_accuracy: 0.0161 - val_loss: 4.2216\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.0098 - loss: 4.5541 - val_accuracy: 0.0161 - val_loss: 4.1911\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.0236 - loss: 4.4985 - val_accuracy: 0.0161 - val_loss: 4.2059\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.0162 - loss: 4.4730 - val_accuracy: 0.0161 - val_loss: 4.1833\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.0107 - loss: 4.4975 - val_accuracy: 0.0161 - val_loss: 4.1717\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.0145 - loss: 4.4815 - val_accuracy: 0.0161 - val_loss: 4.1757\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.0185 - loss: 4.4643 - val_accuracy: 0.0161 - val_loss: 4.1818\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.0150 - loss: 4.4460 - val_accuracy: 0.0161 - val_loss: 4.1814\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.0114 - loss: 4.4680 - val_accuracy: 0.0161 - val_loss: 4.1726\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.0153 - loss: 4.4553 - val_accuracy: 0.0161 - val_loss: 4.1923\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.0159 - loss: 4.3905 - val_accuracy: 0.0161 - val_loss: 4.1828\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.0168 - loss: 4.4209 - val_accuracy: 0.0161 - val_loss: 4.1719\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.0180 - loss: 4.4175 - val_accuracy: 0.0161 - val_loss: 4.1974\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.0103 - loss: 4.4173 - val_accuracy: 0.0161 - val_loss: 4.1864\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.0147 - loss: 4.4449 - val_accuracy: 0.0161 - val_loss: 4.1727\n",
            "Epoch 16/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.0129 - loss: 4.3858 - val_accuracy: 0.0161 - val_loss: 4.1714\n",
            "Epoch 17/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.0147 - loss: 4.4108 - val_accuracy: 0.0161 - val_loss: 4.1585\n",
            "Epoch 18/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.0149 - loss: 4.3976 - val_accuracy: 0.0161 - val_loss: 4.2151\n",
            "Epoch 19/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.0199 - loss: 4.3782 - val_accuracy: 0.0161 - val_loss: 4.1932\n",
            "Epoch 20/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.0162 - loss: 4.3754 - val_accuracy: 0.0161 - val_loss: 4.1811\n",
            "\n",
            " Training MLP with activation=tanh and optimizer=RMSprop\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.0129 - loss: 4.6607 - val_accuracy: 0.0161 - val_loss: 4.2398\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.0130 - loss: 4.5417 - val_accuracy: 0.0161 - val_loss: 4.2590\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.0169 - loss: 4.5268 - val_accuracy: 0.0161 - val_loss: 4.2006\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.0172 - loss: 4.5170 - val_accuracy: 0.0161 - val_loss: 4.2366\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.0162 - loss: 4.4698 - val_accuracy: 0.0161 - val_loss: 4.2658\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.0138 - loss: 4.4937 - val_accuracy: 0.0161 - val_loss: 4.2370\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.0161 - loss: 4.4738 - val_accuracy: 0.0161 - val_loss: 4.2498\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.0122 - loss: 4.4851 - val_accuracy: 0.0161 - val_loss: 4.2287\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.0151 - loss: 4.4643 - val_accuracy: 0.0161 - val_loss: 4.2121\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.0175 - loss: 4.4164 - val_accuracy: 0.0161 - val_loss: 4.2175\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.0109 - loss: 4.4561 - val_accuracy: 0.0161 - val_loss: 4.2290\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.0166 - loss: 4.4196 - val_accuracy: 0.0161 - val_loss: 4.2099\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.0163 - loss: 4.4167 - val_accuracy: 0.0161 - val_loss: 4.2171\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.0158 - loss: 4.4338 - val_accuracy: 0.0161 - val_loss: 4.1943\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.0136 - loss: 4.3961 - val_accuracy: 0.0161 - val_loss: 4.2362\n",
            "Epoch 16/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.0136 - loss: 4.4138 - val_accuracy: 0.0161 - val_loss: 4.1891\n",
            "Epoch 17/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.0142 - loss: 4.3901 - val_accuracy: 0.0161 - val_loss: 4.1808\n",
            "Epoch 18/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.0141 - loss: 4.4079 - val_accuracy: 0.0161 - val_loss: 4.1965\n",
            "Epoch 19/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.0126 - loss: 4.4228 - val_accuracy: 0.0161 - val_loss: 4.2042\n",
            "Epoch 20/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.0171 - loss: 4.3776 - val_accuracy: 0.0161 - val_loss: 4.1919\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Flatten input if image shaped\n",
        "X_train = X_train.reshape(len(X_train), -1)\n",
        "X_test = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "activation_functions = ['relu', 'tanh']\n",
        "# Define optimizers as callables (not pre-built instances)\n",
        "optimizers = {\n",
        "    \"SGD\": lambda: SGD(learning_rate=0.01, momentum=0.9),\n",
        "    \"Adam\": lambda: Adam(learning_rate=0.001),\n",
        "    \"RMSprop\": lambda: RMSprop(learning_rate=0.001),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for act_func in activation_functions:\n",
        "    for opt_name, opt_fn in optimizers.items():\n",
        "        print(f\"\\n Training MLP with activation={act_func} and optimizer={opt_name}\")\n",
        "\n",
        "        model = Sequential([\n",
        "            Input(shape=(X_train.shape[1],)),   #  cleaner than input_shape in Dense\n",
        "            Dense(512, activation=act_func),\n",
        "            Dropout(0.3),\n",
        "            Dense(256, activation=act_func),\n",
        "            Dropout(0.3),\n",
        "            Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        #  fresh optimizer instance\n",
        "        optimizer = opt_fn()\n",
        "\n",
        "        model.compile(optimizer=optimizer,\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=20,\n",
        "            batch_size=64,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        results[(act_func, opt_name)] = history.history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ogdXiyX5pd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e852ecf6-290e-45e1-f6db-bb6cdd5fd051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'english-handwritten-characters-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/english-handwritten-characters-dataset\n",
            "                image label\n",
            "0  Img/img001-001.png     0\n",
            "1  Img/img001-002.png     0\n",
            "2  Img/img001-003.png     0\n",
            "3  Img/img001-004.png     0\n",
            "4  Img/img001-005.png     0\n",
            "X shape: (3410, 64, 64)\n",
            "y shape: (3410,)\n",
            "Classes: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H'\n",
            " 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z'\n",
            " 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "X_train shape: (2728, 4096)\n",
            "X_test shape: (682, 4096)\n",
            "y_train shape: (2728, 62)\n",
            "y_test shape: (682, 62)\n",
            "\n",
            "===== Perceptron Learning Algorithm (PLA) =====\n",
            "Epoch 1/5 completed\n",
            "Epoch 2/5 completed\n",
            "Epoch 3/5 completed\n",
            "Epoch 4/5 completed\n",
            "Epoch 5/5 completed\n",
            "\n",
            "PLA Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        11\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.33      0.09      0.14        11\n",
            "           3       0.00      0.00      0.00        11\n",
            "           4       0.17      0.09      0.12        11\n",
            "           5       0.00      0.00      0.00        11\n",
            "           6       0.00      0.00      0.00        11\n",
            "           7       0.00      0.00      0.00        11\n",
            "           8       0.00      0.00      0.00        11\n",
            "           9       0.24      0.73      0.36        11\n",
            "           A       0.00      0.00      0.00        11\n",
            "           B       0.00      0.00      0.00        11\n",
            "           C       0.00      0.00      0.00        11\n",
            "           D       0.50      0.09      0.15        11\n",
            "           E       0.00      0.00      0.00        11\n",
            "           F       0.00      0.00      0.00        11\n",
            "           G       0.00      0.00      0.00        11\n",
            "           H       0.38      0.27      0.32        11\n",
            "           I       0.00      0.00      0.00        11\n",
            "           J       0.00      0.00      0.00        11\n",
            "           K       0.00      0.00      0.00        11\n",
            "           L       0.00      0.00      0.00        11\n",
            "           M       0.00      0.00      0.00        11\n",
            "           N       0.00      0.00      0.00        11\n",
            "           O       0.33      0.09      0.14        11\n",
            "           P       0.27      0.82      0.41        11\n",
            "           Q       0.00      0.00      0.00        11\n",
            "           R       0.75      0.27      0.40        11\n",
            "           S       0.33      0.27      0.30        11\n",
            "           T       0.21      0.64      0.31        11\n",
            "           U       0.09      0.82      0.16        11\n",
            "           V       0.00      0.00      0.00        11\n",
            "           W       0.00      0.00      0.00        11\n",
            "           X       0.21      0.36      0.27        11\n",
            "           Y       0.00      0.00      0.00        11\n",
            "           Z       0.00      0.00      0.00        11\n",
            "           a       0.00      0.00      0.00        11\n",
            "           b       0.08      0.09      0.08        11\n",
            "           c       0.03      0.91      0.06        11\n",
            "           d       0.00      0.00      0.00        11\n",
            "           e       0.00      0.00      0.00        11\n",
            "           f       0.00      0.00      0.00        11\n",
            "           g       0.20      0.55      0.29        11\n",
            "           h       0.00      0.00      0.00        11\n",
            "           i       0.00      0.00      0.00        11\n",
            "           j       0.50      0.18      0.27        11\n",
            "           k       0.00      0.00      0.00        11\n",
            "           l       0.00      0.00      0.00        11\n",
            "           m       0.00      0.00      0.00        11\n",
            "           n       0.00      0.00      0.00        11\n",
            "           o       0.00      0.00      0.00        11\n",
            "           p       0.00      0.00      0.00        11\n",
            "           q       0.50      0.09      0.15        11\n",
            "           r       0.00      0.00      0.00        11\n",
            "           s       0.25      0.09      0.13        11\n",
            "           t       0.00      0.00      0.00        11\n",
            "           u       0.20      0.27      0.23        11\n",
            "           v       0.00      0.00      0.00        11\n",
            "           w       0.00      0.00      0.00        11\n",
            "           x       0.00      0.00      0.00        11\n",
            "           y       0.00      0.00      0.00        11\n",
            "           z       0.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.11       682\n",
            "   macro avg       0.09      0.11      0.07       682\n",
            "weighted avg       0.09      0.11      0.07       682\n",
            "\n",
            "\n",
            "===== Multi-Layer Perceptron (MLP) Training =====\n",
            "\n",
            "Training MLP with activation=relu, optimizer=sgd_0.01...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training MLP with activation=relu, optimizer=sgd_0.001...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training MLP with activation=relu, optimizer=adam_0.01...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training MLP with activation=relu, optimizer=adam_0.001...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training MLP with activation=sigmoid, optimizer=sgd_0.01...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unknown variable: <Variable path=sequential_33/dense_99/kernel, shape=(4096, 256), dtype=float32, value=[[-0.03475494 -0.00132901  0.02166515 ... -0.01036663  0.00619852\n   0.01706775]\n [ 0.00657668  0.00020749 -0.03616791 ...  0.03207246  0.02842291\n   0.00177043]\n [ 0.03224905  0.00221035  0.01544712 ... -0.00378673  0.03094978\n  -0.02744707]\n ...\n [-0.03215418 -0.01920486 -0.01611332 ...  0.00857177 -0.01570316\n  -0.01311625]\n [-0.01956653  0.02416939  0.03698403 ...  0.00999744 -0.03592919\n   0.02028155]\n [-0.00641564 -0.03170066 -0.0007044  ...  0.02929342 -0.03093882\n   0.03491192]]>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3219969141.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         history = mlp.fit(\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_check_variables_are_known\u001b[0;34m(self, variables)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_variables_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    410\u001b[0m                     \u001b[0;34mf\"Unknown variable: {v}. This optimizer can only \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0;34m\"be called for the variables it was originally built with. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown variable: <Variable path=sequential_33/dense_99/kernel, shape=(4096, 256), dtype=float32, value=[[-0.03475494 -0.00132901  0.02166515 ... -0.01036663  0.00619852\n   0.01706775]\n [ 0.00657668  0.00020749 -0.03616791 ...  0.03207246  0.02842291\n   0.00177043]\n [ 0.03224905  0.00221035  0.01544712 ... -0.00378673  0.03094978\n  -0.02744707]\n ...\n [-0.03215418 -0.01920486 -0.01611332 ...  0.00857177 -0.01570316\n  -0.01311625]\n [-0.01956653  0.02416939  0.03698403 ...  0.00999744 -0.03592919\n   0.02028155]\n [-0.00641564 -0.03170066 -0.0007044  ...  0.02929342 -0.03093882\n   0.03491192]]>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance."
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"dhruvildave/english-handwritten-characters-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(os.path.join(path, 'english.csv'))\n",
        "print(df.head())\n",
        "\n",
        "img_size = 64  # resize to fixed size\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    fil = row['image']\n",
        "    label = row['label']\n",
        "    img_path = os.path.join(path, fil)\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        X.append(img)\n",
        "        y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "# Flatten and normalize for PLA/MLP\n",
        "X_flat = X.reshape(-1, img_size * img_size) / 255.0\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y_encoded_onehot = to_categorical(y_encoded)\n",
        "num_classes = y_encoded_onehot.shape[1]\n",
        "\n",
        "print(\"Classes:\", le.classes_)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_flat, y_encoded_onehot, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# PLA Classifier\n",
        "class PLA:\n",
        "    def __init__(self, input_dim, num_classes, lr=0.01, epochs=10):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.num_classes = num_classes\n",
        "        self.W = np.zeros((input_dim, num_classes))\n",
        "        self.b = np.zeros(num_classes)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                xi = X[i]\n",
        "                target = np.argmax(y[i])\n",
        "                scores = np.dot(xi, self.W) + self.b\n",
        "                y_hat = np.argmax(scores)\n",
        "                if y_hat != target:\n",
        "                    self.W[:, target] += self.lr * xi\n",
        "                    self.W[:, y_hat] -= self.lr * xi\n",
        "            print(f\"Epoch {epoch+1}/{self.epochs} completed\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = np.dot(X, self.W) + self.b\n",
        "        return np.argmax(scores, axis=1)\n",
        "\n",
        "print(\"\\n===== Perceptron Learning Algorithm (PLA) =====\")\n",
        "pla = PLA(input_dim=X_train.shape[1], num_classes=num_classes, lr=0.01, epochs=5)\n",
        "pla.fit(X_train, y_train)\n",
        "\n",
        "y_pred_pla = pla.predict(X_test)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"\\nPLA Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_pla, target_names=le.classes_.astype(str), zero_division=0))\n",
        "\n",
        "\n",
        "# MLP systematic training and evaluation\n",
        "print(\"\\n===== Multi-Layer Perceptron (MLP) Training =====\")\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Hyperparameters\n",
        "activations = ['relu', 'sigmoid', 'tanh']\n",
        "optimizers = {\n",
        "    'sgd_0.01': SGD(learning_rate=0.01),\n",
        "    'sgd_0.001': SGD(learning_rate=0.001),\n",
        "    'adam_0.01': Adam(learning_rate=0.01),\n",
        "    'adam_0.001': Adam(learning_rate=0.001)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for act in activations:\n",
        "    for opt_name, opt in optimizers.items():\n",
        "        print(f\"\\nTraining MLP with activation={act}, optimizer={opt_name}...\")\n",
        "\n",
        "        # Build model\n",
        "        mlp = Sequential([\n",
        "            Input(shape=(X_train.shape[1],)),\n",
        "            Dense(256, activation=act),\n",
        "            Dropout(0.3),\n",
        "            Dense(128, activation=act),\n",
        "            Dropout(0.3),\n",
        "            Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        mlp.compile(optimizer=opt,\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "        # Train\n",
        "        history = mlp.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=20,\n",
        "            batch_size=64,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        test_loss, test_acc = mlp.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = mlp.predict(X_test, verbose=0)\n",
        "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "        y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "        report = classification_report(\n",
        "            y_true, y_pred_classes,\n",
        "            target_names=le.classes_.astype(str),\n",
        "            zero_division=0,\n",
        "            output_dict=True\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            'activation': act,\n",
        "            'optimizer': opt_name,\n",
        "            'test_acc': test_acc,\n",
        "            'test_loss': test_loss,\n",
        "            'macro_f1': report['macro avg']['f1-score'],\n",
        "            'weighted_f1': report['weighted avg']['f1-score']\n",
        "        })\n",
        "\n",
        "# Put results in DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='test_acc', ascending=False)\n",
        "\n",
        "print(\"\\n===== All Results =====\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install pandoc -y\n",
        "\n",
        "!jupyter nbconvert --to latex \"/content/drive/MyDrive/Colab_Notebooks/ML_Assignment5.ipynb\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDAqux0rY-6L",
        "outputId": "a6a04645-3ae6-4fd9-ac5f-ccb6deac7e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pandoc is already the newest version (2.9.2.1-3ubuntu2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab_Notebooks/ML_Assignment5.ipynb to latex\n",
            "[NbConvertApp] Support files will be in ML_Assignment5_files/\n",
            "[NbConvertApp] Making directory /content/drive/MyDrive/Colab_Notebooks/ML_Assignment5_files\n",
            "[NbConvertApp] Writing 111465 bytes to /content/drive/MyDrive/Colab_Notebooks/ML_Assignment5.tex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/Colab_Notebooks/ML_Assignment5.tex')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mEk8YFxGZaNi",
        "outputId": "7191bcf9-96e8-48a3-f468-828cbe0df5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_11fd4f1f-35ab-43a5-9261-8905438b58d9\", \"ML_Assignment5.tex\", 116290)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}